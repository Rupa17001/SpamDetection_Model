{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# with pandas library reading csv file that is separated on the basis of tab and as the data is unstructures the columns have been given names \"label\", \"message\"\n",
    "messages = pd.read_csv(r'C:\\Users\\Admin\\Desktop\\nlp\\smsspamcollection\\SMSSpamCollection.txt', sep='\\t',\n",
    "                       names=[\"label\", \"message\"])\n",
    "\n",
    "# Corpus is the blank list\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the extra space and words that has no meaning are removed here using regex , stopwords anf lemmatization (just to reduce text)\n",
    "# then the sorted text is added in corpus[] list\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# text inside the corpus is being converted into vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(max_features=2500)\n",
    "X = tf.fit_transform(corpus).toarray()\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ham   spam\n",
      "0      True  False\n",
      "1      True  False\n",
      "2     False   True\n",
      "3      True  False\n",
      "4      True  False\n",
      "...     ...    ...\n",
      "5567  False   True\n",
      "5568   True  False\n",
      "5569   True  False\n",
      "5570   True  False\n",
      "5571   True  False\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y=pd.get_dummies(messages['label'])\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True ... False False False]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y=pd.get_dummies(messages['label'])\n",
    "y=y.iloc[:,1].values\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False ... False  True False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# Training model using Naive bayes classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=spam_detect_model.predict(X_test)\n",
    "\n",
    "print (y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
